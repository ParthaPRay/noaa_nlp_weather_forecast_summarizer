{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DEVELOPED BY**\n",
        "\n",
        "**PARTHA PRATIM RAY**\n",
        "\n",
        "**https://github.com/ParthaPRay/**\n",
        "\n",
        "**parthapratimray1986@gmail.com**"
      ],
      "metadata": {
        "id": "PCZ61qkg82j2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD0dl8Fy50Qu",
        "outputId": "c4493017-b5b1-4459-9f64-8fc92d958e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.7.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n",
            "Requirement already satisfied: thinc in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (8.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
            "Collecting gradio (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.27.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc->-r requirements.txt (line 4)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc->-r requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 6)) (2024.12.14)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (0.28.1)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.10.12)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (11.0.0)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading starlette-0.43.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio->-r requirements.txt (line 7)) (14.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 7)) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 1)) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 1)) (7.1.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 1)) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0mMPuPy6WYP",
        "outputId": "0c9f6d91-9f0a-401d-c0ed-9f3f976a5f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.7.3\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.7.3/en_core_web_trf-3.7.3-py3-none-any.whl (457.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-trf==3.7.3) (3.7.5)\n",
            "Collecting spacy-curated-transformers<0.3.0,>=0.2.0 (from en-core-web-trf==3.7.3)\n",
            "  Downloading spacy_curated_transformers-0.2.2-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.26.4)\n",
            "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3)\n",
            "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
            "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3)\n",
            "  Downloading curated_tokenizers-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2.5.1+cu121)\n",
            "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.10/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2024.11.6)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<0.3.0,>=0.2.0->en-core-web-trf==3.7.3) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-trf==3.7.3) (0.1.2)\n",
            "Downloading spacy_curated_transformers-0.2.2-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
            "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.7.3 spacy-curated-transformers-0.2.2\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_trf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESTART SESSION"
      ],
      "metadata": {
        "id": "FgB3uRfUKdrl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507,
          "referenced_widgets": [
            "0f577c5a18d34b23bf05c2a7dbfed248",
            "8639da808d8940b8948b260380d4cabb",
            "e0f7861b3117495f90b37059419e3aa3",
            "ada246812a5f492a984447d141db25c1",
            "5c309b7a90a349d9929b117525a21f29",
            "18d0af05ea5244f2a92a0c2beed74f46",
            "b94d2593581b4570a72404d8d16e4756",
            "493310099b014ca89a2793f3fae98e3f",
            "94e64e1fed494c52959af81c478394ed",
            "1e59d6804125469086b44d0ddc6ae424",
            "6fbc8672b1ca4e9ab2a58d5ff6129e88",
            "1f1ea75388684987af26390454924d3d",
            "da38f816e95244e5a2641d8ceefdcd15",
            "94ca0baefcd944b58a7657085d47073a",
            "e80914275f8f4eb88aca04dca74021d5",
            "49cd21d2648847ed9419f003e0f797ca",
            "458cc19f09fb4fe1be2af54b8236b8a9",
            "ec9963ef96d743438a405e7c978c200a",
            "ed96ddc966a4483e9cfd8abb8e1e570a",
            "e8fc4ad9576240b890aa00ef303edc08",
            "16a55e5cdc564beeab0d8e8eda31f43d",
            "90b7807bb2c248f4bb272f310ba1dc46",
            "f210c723a31e40eba67ce43da00394b2",
            "5b5a11135cc94438bc2ae769da9725dd",
            "7d89a4df43314810b5ca7405d53d9eca",
            "083b8047c9014a64b79f67e055b90c86",
            "b97a56a39aa046c7a1b0be31784b3641",
            "51050718cb8441b580a551ef1f245065",
            "d415697d704245bb876114dfa6220eb2",
            "41328f3b3a824d57bc64b409f626df70",
            "4933bc811431441c90e3336c85c5aeed",
            "48193d767eb047a38676ca4039474d29",
            "1bac097b31074a28ae1cdce5028b2242",
            "c15bd4b8605347bc88f1bbc6af9df971",
            "a6e9102a6d4546d7bb430563174c34d8",
            "a81ba9dfe9b8478c9a223a78b4f67e6c",
            "377a17c8d37a45058a8e45a97816f082",
            "8eeb2218bee848808021730bab123c96",
            "ec592025b3994a7992df6f881294774a",
            "8d69a13b662b499a8b02a91231a42980",
            "9aae2b07073b4caab72f6d8bd4fb698a",
            "8e53de26c836482688df4622bc6e46d1",
            "fdf7bf6f2ec8417f8070744a08ffa451",
            "ddcbafb4751a4010911ffdb9a8b9dedb",
            "14c83e4c71a2467bbb37200eb9a9dd3c",
            "6c5e26c7c4c54b05a858d368f84d4b4b",
            "650befdd647a4ed3a079fb4e02254cbe",
            "22772e67433542389a1a4d08f17aec34",
            "0463355d89f44f8080128e6597ce63c5",
            "013fec8da569414aa1dcf6160f02b3d4",
            "6146de77d4274a87bc4620eabd4489cc",
            "52f2088433284da0b6ac3ba985f4347f",
            "6ded762e089d41f1847a42af3522fb1c",
            "dbb289860a1d47f1ae28beb98b71caa9",
            "aa77bdce55e3486baaa5c1243482d113",
            "4a538028cb4e4f4d936f60e3ae67d88a",
            "b5f2e9c233c042fcbe8ecd4726723f18",
            "d07d17d3a2b44882bb28721552804a71",
            "b6e8bb0758db442e80ebeae46db2b599",
            "ff5e7a2d7d65436a950d27185a739a8a",
            "176753ef63344f41b0285850eb01662b",
            "11b0d5f695554a208e9b890f1c35c550",
            "df1c0431fdb24882bfa3f214b3940717",
            "b5246de9f33a47339418d6b34600e424",
            "28920e8aa68e461bbba07f1514448504",
            "d1f2a65d018044dbb364c3995d17f1cf"
          ]
        },
        "id": "Yc0RzCGO54Ny",
        "outputId": "cfceb05b-fdee-4aa9-c53c-51dcbb4d3228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:GPU not available or not configured: Cannot use GPU, CuPy is not installed\n",
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(filelike, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f577c5a18d34b23bf05c2a7dbfed248"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f1ea75388684987af26390454924d3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f210c723a31e40eba67ce43da00394b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c15bd4b8605347bc88f1bbc6af9df971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14c83e4c71a2467bbb37200eb9a9dd3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a538028cb4e4f4d936f60e3ae67d88a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
            "Your max_length is set to 100, but your input_length is only 55. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "Weather today is mostly cloudy with occasional rain showers. Temperatures will remain cool, ranging between 15°C to 20°C. Tomorrow, conditions are likely to improve with more sunshine.\n"
          ]
        }
      ],
      "source": [
        "### BASIC CODE\n",
        "####### Simulated Weather Report Summarization\n",
        "\n",
        "# Text summarizer\n",
        "\n",
        "### facebook/bart-large-cnn\n",
        "\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "from thinc.api import set_gpu_allocator, require_gpu\n",
        "import logging\n",
        "\n",
        "# Configure logging for debug messages\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Step 1: Use GPU if available\n",
        "try:\n",
        "    set_gpu_allocator(\"pytorch\")\n",
        "    require_gpu(0)\n",
        "    logging.info(\"Using GPU for computation.\")\n",
        "except Exception as e:\n",
        "    logging.warning(\"GPU not available or not configured: %s\", e)\n",
        "\n",
        "# Step 2: Load the spaCy language model\n",
        "try:\n",
        "    logging.info(\"Loading spaCy language model.\")\n",
        "    nlp = spacy.load(\"en_core_web_trf\")  # Transformer-enabled spaCy model\n",
        "    logging.info(\"spaCy model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load spaCy model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 3: Load the BART summarization pipeline from Hugging Face\n",
        "try:\n",
        "    logging.info(\"Loading BART summarization pipeline.\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    logging.info(\"BART pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load BART model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 4: Define the text summarization function\n",
        "def summarize_text(article, max_length=130, min_length=30, debug=False):\n",
        "    try:\n",
        "        logging.info(\"Processing text with spaCy.\")\n",
        "        doc = nlp(article)\n",
        "        logging.debug(\"spaCy processing complete. Extracting sentences.\")\n",
        "\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        logging.debug(\"Extracted %d sentences from the article.\", len(sentences))\n",
        "\n",
        "        if debug:\n",
        "            logging.debug(\"Sentences: %s\", sentences)\n",
        "\n",
        "        logging.info(\"Generating summary using BART model.\")\n",
        "        summary = summarizer(article, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "\n",
        "        logging.info(\"Summary generated successfully.\")\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        logging.error(\"Error during summarization: %s\", e)\n",
        "        raise\n",
        "\n",
        "# Step 5: Sample text input\n",
        "ARTICLE = \"\"\"Weather today is mostly cloudy with occasional rain showers. Temperatures will remain cool, ranging between 15°C to 20°C. Wind speeds are expected to reach up to 30 km/h in some regions. Tomorrow, conditions are likely to improve with more sunshine.\"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        logging.info(\"Starting summarization task.\")\n",
        "        summary = summarize_text(ARTICLE, max_length=100, min_length=20, debug=True)\n",
        "        print(\"\\nSummary:\")\n",
        "        print(summary)\n",
        "        logging.info(\"Summarization task completed successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.critical(\"Summarization task failed: %s\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z9YU3LRHRaR",
        "outputId": "e2a6695e-4f69-438c-883e-8eaaf399f52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "    Hugging Face token (HF_TOKEN) not found.\n",
            "    Proceeding without authentication may lead to rate limiting.\n",
            "    To set the token, add it to Colab secrets or set it directly in the notebook.\n",
            "    \n",
            "WARNING:root:GPU not available or not configured: Cannot use GPU, CuPy is not installed\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "The temperature will be 62°F with patchy fog. A chance of rain showers and patchy Fog before 9am, then patchy. fog and showers and thunderstorms between 9am and noon. Cloudy. High near 62, with temperatures falling to around 60 in the afternoon. Chance of precipitation is 90%. New rainfall amounts between a half and three quarters of an inch possible.\n"
          ]
        }
      ],
      "source": [
        "################## NOAA v1 working\n",
        "\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "from thinc.api import set_gpu_allocator, require_gpu\n",
        "import logging\n",
        "import requests\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Configure logging for debug messages\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Constants\n",
        "NOAA_ENDPOINT = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "\n",
        "# Optional: Set Hugging Face token if available\n",
        "# To set the token, add it to Colab secrets or set it directly in the notebook.\n",
        "# For example, you can set it directly (not recommended for shared notebooks):\n",
        "# os.environ[\"HF_TOKEN\"] = \"your_huggingface_token_here\"\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "if HF_TOKEN:\n",
        "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "    logging.info(\"Hugging Face token found and set.\")\n",
        "else:\n",
        "    logging.warning(\"\"\"\n",
        "    Hugging Face token (HF_TOKEN) not found.\n",
        "    Proceeding without authentication may lead to rate limiting.\n",
        "    To set the token, add it to Colab secrets or set it directly in the notebook.\n",
        "    \"\"\")\n",
        "\n",
        "# Step 1: Use GPU if available\n",
        "# Attempt to use GPU; if unavailable, fallback to CPU\n",
        "try:\n",
        "    set_gpu_allocator(\"pytorch\")\n",
        "    require_gpu(0)\n",
        "    logging.info(\"Using GPU for computation.\")\n",
        "    device = 0  # GPU device\n",
        "except Exception as e:\n",
        "    logging.warning(\"GPU not available or not configured: %s\", e)\n",
        "    device = -1  # CPU device\n",
        "\n",
        "# Step 2: Load the spaCy language model\n",
        "try:\n",
        "    logging.info(\"Loading spaCy language model.\")\n",
        "    nlp = spacy.load(\"en_core_web_trf\")  # Transformer-enabled spaCy model\n",
        "    logging.info(\"spaCy model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load spaCy model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 3: Load the BART summarization pipeline from Hugging Face\n",
        "try:\n",
        "    logging.info(\"Loading BART summarization pipeline.\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
        "    logging.info(\"BART pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load BART model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 4: Define the function to fetch weather data from NOAA's NWS API\n",
        "def fetch_weather_data(latitude, longitude):\n",
        "    \"\"\"\n",
        "    Fetch weather forecast data from NOAA's NWS API for the given latitude and longitude.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude of the location.\n",
        "        longitude (float): Longitude of the location.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the forecast data.\n",
        "    \"\"\"\n",
        "    endpoint = NOAA_ENDPOINT.format(latitude=latitude, longitude=longitude)\n",
        "    headers = {\n",
        "        'User-Agent': USER_AGENT\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Fetching metadata from NOAA NWS API.\")\n",
        "        response = requests.get(endpoint, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract the forecast URL\n",
        "        forecast_url = data['properties']['forecast']\n",
        "\n",
        "        logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "        forecast_response = requests.get(forecast_url, headers=headers, timeout=10)\n",
        "        forecast_response.raise_for_status()\n",
        "        forecast_data = forecast_response.json()\n",
        "\n",
        "        return forecast_data\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        logging.error(\"HTTP error occurred: %s\", http_err)\n",
        "    except requests.exceptions.ConnectionError as conn_err:\n",
        "        logging.error(\"Connection error occurred: %s\", conn_err)\n",
        "    except requests.exceptions.Timeout as timeout_err:\n",
        "        logging.error(\"Timeout error occurred: %s\", timeout_err)\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        logging.error(\"Request exception: %s\", req_err)\n",
        "    except KeyError as key_err:\n",
        "        logging.error(\"Key error: %s\", key_err)\n",
        "    except Exception as e:\n",
        "        logging.error(\"An unexpected error occurred: %s\", e)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Step 5: Define the function to parse weather JSON into a coherent paragraph\n",
        "def parse_weather_data(forecast_data):\n",
        "    \"\"\"\n",
        "    Parse the NOAA NWS JSON response and construct a descriptive paragraph.\n",
        "\n",
        "    Args:\n",
        "        forecast_data (dict): JSON data from NOAA NWS API.\n",
        "\n",
        "    Returns:\n",
        "        str: A well-formed paragraph describing the weather forecast.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Parsing weather data.\")\n",
        "        periods = forecast_data['properties']['periods']\n",
        "\n",
        "        paragraphs = []\n",
        "\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(\"Parsed forecast for %s: %s\", name, forecast_paragraph)\n",
        "\n",
        "        full_paragraph = \" \".join(paragraphs)\n",
        "        logging.info(\"Weather data parsed into paragraph successfully.\")\n",
        "        return full_paragraph\n",
        "\n",
        "    except KeyError as key_err:\n",
        "        logging.error(\"Key error while parsing weather data: %s\", key_err)\n",
        "    except Exception as e:\n",
        "        logging.error(\"Error parsing weather data: %s\", e)\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# Step 6: Define the text summarization function\n",
        "def summarize_text(article, max_length=150, min_length=40, debug=False):\n",
        "    \"\"\"\n",
        "    Summarize the given text using the BART model.\n",
        "\n",
        "    Args:\n",
        "        article (str): The text to summarize.\n",
        "        max_length (int): Maximum length of the summary.\n",
        "        min_length (int): Minimum length of the summary.\n",
        "        debug (bool): If True, enables debug logging.\n",
        "\n",
        "    Returns:\n",
        "        str: The summarized text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Processing text with spaCy.\")\n",
        "        doc = nlp(article)\n",
        "        logging.debug(\"spaCy processing complete. Extracting sentences.\")\n",
        "\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        logging.debug(\"Extracted %d sentences from the article.\", len(sentences))\n",
        "\n",
        "        if debug:\n",
        "            logging.debug(\"Sentences: %s\", sentences)\n",
        "\n",
        "        logging.info(\"Generating summary using BART model.\")\n",
        "        summary = summarizer(\n",
        "            article,\n",
        "            max_length=max_length,\n",
        "            min_length=min_length,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "        logging.info(\"Summary generated successfully.\")\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        logging.error(\"Error during summarization: %s\", e)\n",
        "        raise\n",
        "\n",
        "# Step 7: Main function to integrate all steps\n",
        "def main(latitude, longitude):\n",
        "    \"\"\"\n",
        "    Main function to fetch, parse, and summarize weather data.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude of the location.\n",
        "        longitude (float): Longitude of the location.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Starting weather data retrieval and summarization.\")\n",
        "\n",
        "        # Fetch weather data\n",
        "        forecast_data = fetch_weather_data(latitude, longitude)\n",
        "\n",
        "        if not forecast_data:\n",
        "            logging.warning(\"No forecast data retrieved.\")\n",
        "            return\n",
        "\n",
        "        # Parse weather data into paragraph\n",
        "        weather_paragraph = parse_weather_data(forecast_data)\n",
        "\n",
        "        if not weather_paragraph:\n",
        "            logging.warning(\"No weather information available to summarize.\")\n",
        "            return\n",
        "\n",
        "        # Summarize the paragraph\n",
        "        summary = summarize_text(weather_paragraph, max_length=150, min_length=40, debug=True)\n",
        "\n",
        "        print(\"\\nSummary:\")\n",
        "        print(summary)\n",
        "        logging.info(\"Summarization task completed successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(\"Summarization task failed: %s\", e)\n",
        "\n",
        "# Step 8: Run the main function with specified coordinates\n",
        "# Define your latitude and longitude here\n",
        "# Example: Dallas, TX (32.7767, -96.7970)\n",
        "LATITUDE = 32.7767\n",
        "LONGITUDE = -96.7970\n",
        "\n",
        "# Alternatively, you can use input prompts to enter coordinates\n",
        "# Uncomment the following lines to enable user input\n",
        "\n",
        "# try:\n",
        "#     LATITUDE = float(input(\"Enter latitude: \"))\n",
        "#     LONGITUDE = float(input(\"Enter longitude: \"))\n",
        "# except ValueError:\n",
        "#     logging.error(\"Invalid input. Please enter numeric values for latitude and longitude.\")\n",
        "#     sys.exit(1)\n",
        "\n",
        "# Execute the main function\n",
        "main(LATITUDE, LONGITUDE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "dSgErUYeQEtH",
        "outputId": "f5b8c35a-0aa1-47d6-8fee-db26e26107c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "    Hugging Face token (HF_TOKEN) not found.\n",
            "    Proceeding without authentication may lead to rate limiting.\n",
            "    To set the token, add it to Colab secrets or set it directly in the notebook.\n",
            "    \n",
            "WARNING:root:GPU not available or not configured: Cannot use GPU, CuPy is not installed\n",
            "/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(filelike, map_location=device))\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c814ac811eb98b76ac.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c814ac811eb98b76ac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "################# NOAAA v2 GRADIO\n",
        "\n",
        "# Text summarization\n",
        "\n",
        "# facebook/bart-large-cnn\n",
        "\n",
        "# NOAA Raw Response + Sumarize weather forecast\n",
        "\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "from thinc.api import set_gpu_allocator, require_gpu\n",
        "import logging\n",
        "import requests\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "import gradio as gr\n",
        "\n",
        "# Configure logging for debug messages\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Constants\n",
        "NOAA_ENDPOINT = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "\n",
        "# Optional: Set Hugging Face token if available\n",
        "# To set the token, add it to Colab secrets or set it directly in the notebook.\n",
        "# For example, you can set it directly (not recommended for shared notebooks):\n",
        "# os.environ[\"HF_TOKEN\"] = \"your_huggingface_token_here\"\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "if HF_TOKEN:\n",
        "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "    logging.info(\"Hugging Face token found and set.\")\n",
        "else:\n",
        "    logging.warning(\"\"\"\n",
        "    Hugging Face token (HF_TOKEN) not found.\n",
        "    Proceeding without authentication may lead to rate limiting.\n",
        "    To set the token, add it to Colab secrets or set it directly in the notebook.\n",
        "    \"\"\")\n",
        "\n",
        "# Step 1: Use GPU if available\n",
        "# Attempt to use GPU; if unavailable, fallback to CPU\n",
        "try:\n",
        "    set_gpu_allocator(\"pytorch\")\n",
        "    require_gpu(0)\n",
        "    logging.info(\"Using GPU for computation.\")\n",
        "    device = 0  # GPU device\n",
        "except Exception as e:\n",
        "    logging.warning(\"GPU not available or not configured: %s\", e)\n",
        "    device = -1  # CPU device\n",
        "\n",
        "# Step 2: Load the spaCy language model\n",
        "try:\n",
        "    logging.info(\"Loading spaCy language model.\")\n",
        "    nlp = spacy.load(\"en_core_web_trf\")  # Transformer-enabled spaCy model\n",
        "    logging.info(\"spaCy model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load spaCy model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 3: Load the BART summarization pipeline from Hugging Face\n",
        "try:\n",
        "    logging.info(\"Loading BART summarization pipeline.\")\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
        "    logging.info(\"BART pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(\"Failed to load BART model: %s\", e)\n",
        "    raise\n",
        "\n",
        "# Step 4: Define the function to fetch weather data from NOAA's NWS API\n",
        "def fetch_weather_data(latitude, longitude):\n",
        "    \"\"\"\n",
        "    Fetch weather forecast data from NOAA's NWS API for the given latitude and longitude.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude of the location.\n",
        "        longitude (float): Longitude of the location.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the forecast data.\n",
        "    \"\"\"\n",
        "    endpoint = NOAA_ENDPOINT.format(latitude=latitude, longitude=longitude)\n",
        "    headers = {\n",
        "        'User-Agent': USER_AGENT\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        logging.info(\"Fetching metadata from NOAA NWS API.\")\n",
        "        response = requests.get(endpoint, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        logging.debug(f\"Metadata Response: {json.dumps(data, indent=2)}\")  # Debug message\n",
        "\n",
        "        # Extract the forecast URL\n",
        "        forecast_url = data['properties']['forecast']\n",
        "\n",
        "        logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "        forecast_response = requests.get(forecast_url, headers=headers, timeout=10)\n",
        "        forecast_response.raise_for_status()\n",
        "        forecast_data = forecast_response.json()\n",
        "        logging.debug(f\"Forecast Response: {json.dumps(forecast_data, indent=2)}\")  # Debug message\n",
        "\n",
        "        return forecast_data\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        logging.error(f\"HTTP error occurred: {http_err}\")\n",
        "    except requests.exceptions.ConnectionError as conn_err:\n",
        "        logging.error(f\"Connection error occurred: {conn_err}\")\n",
        "    except requests.exceptions.Timeout as timeout_err:\n",
        "        logging.error(f\"Timeout error occurred: {timeout_err}\")\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        logging.error(f\"Request exception: {req_err}\")\n",
        "    except KeyError as key_err:\n",
        "        logging.error(f\"Key error: {key_err}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "# Step 5: Define the function to parse weather JSON into a coherent paragraph\n",
        "def parse_weather_data(forecast_data):\n",
        "    \"\"\"\n",
        "    Parse the NOAA NWS JSON response and construct a descriptive paragraph.\n",
        "\n",
        "    Args:\n",
        "        forecast_data (dict): JSON data from NOAA NWS API.\n",
        "\n",
        "    Returns:\n",
        "        str: A well-formed paragraph describing the weather forecast.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Parsing weather data.\")\n",
        "        periods = forecast_data['properties']['periods']\n",
        "\n",
        "        paragraphs = []\n",
        "\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(f\"Parsed forecast for {name}: {forecast_paragraph}\")\n",
        "\n",
        "        full_paragraph = \" \".join(paragraphs)\n",
        "        logging.info(\"Weather data parsed into paragraph successfully.\")\n",
        "        logging.debug(f\"Full Paragraph: {full_paragraph}\")  # Debug message\n",
        "        return full_paragraph\n",
        "\n",
        "    except KeyError as key_err:\n",
        "        logging.error(f\"Key error while parsing weather data: {key_err}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error parsing weather data: {e}\")\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# Step 6: Define the text summarization function\n",
        "def summarize_text(article, max_length=150, min_length=40, debug=False):\n",
        "    \"\"\"\n",
        "    Summarize the given text using the BART model.\n",
        "\n",
        "    Args:\n",
        "        article (str): The text to summarize.\n",
        "        max_length (int): Maximum length of the summary.\n",
        "        min_length (int): Minimum length of the summary.\n",
        "        debug (bool): If True, enables debug logging.\n",
        "\n",
        "    Returns:\n",
        "        str: The summarized text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Processing text with spaCy.\")\n",
        "        doc = nlp(article)\n",
        "        logging.debug(\"spaCy processing complete. Extracting sentences.\")\n",
        "\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        logging.debug(f\"Extracted {len(sentences)} sentences from the article.\")\n",
        "\n",
        "        if debug:\n",
        "            logging.debug(f\"Sentences: {sentences}\")\n",
        "\n",
        "        logging.info(\"Generating summary using BART model.\")\n",
        "        summary = summarizer(\n",
        "            article,\n",
        "            max_length=max_length,\n",
        "            min_length=min_length,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "        logging.info(\"Summary generated successfully.\")\n",
        "        return summary[0]['summary_text']\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during summarization: {e}\")\n",
        "        raise\n",
        "\n",
        "# Step 7: Define the Gradio interface function\n",
        "def weather_summarizer(latitude, longitude):\n",
        "    \"\"\"\n",
        "    Gradio interface function to fetch, parse, and summarize weather data.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude of the location.\n",
        "        longitude (float): Longitude of the location.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Raw weather data (JSON string) and summarized weather forecast.\n",
        "    \"\"\"\n",
        "    # Fetch weather data\n",
        "    forecast_data = fetch_weather_data(latitude, longitude)\n",
        "\n",
        "    if not forecast_data:\n",
        "        return \"No forecast data retrieved.\", \"Unable to generate summary.\"\n",
        "\n",
        "    # Parse weather data into paragraph\n",
        "    weather_paragraph = parse_weather_data(forecast_data)\n",
        "\n",
        "    if not weather_paragraph:\n",
        "        return \"No weather information available to summarize.\", \"Unable to generate summary.\"\n",
        "\n",
        "    # Summarize the paragraph\n",
        "    summary = summarize_text(weather_paragraph, max_length=150, min_length=40, debug=True)\n",
        "\n",
        "    # Prepare raw data for display (pretty-printed JSON)\n",
        "    raw_data = json.dumps(forecast_data, indent=2)\n",
        "\n",
        "    return raw_data, summary\n",
        "\n",
        "# Step 8: Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Weather Summarizer\")\n",
        "    gr.Markdown(\"Enter the latitude and longitude of a location to get a summarized weather forecast.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        latitude_input = gr.Number(label=\"Latitude\", value=32.7767)\n",
        "        longitude_input = gr.Number(label=\"Longitude\", value=-96.7970)\n",
        "\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "\n",
        "    with gr.Row():\n",
        "        raw_output = gr.Textbox(label=\"Raw NOAA API Response\", lines=20)\n",
        "        summary_output = gr.Textbox(label=\"Summarized Weather Forecast\", lines=10)\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=weather_summarizer,\n",
        "        inputs=[latitude_input, longitude_input],\n",
        "        outputs=[raw_output, summary_output]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    **Note:** Ensure that the latitude and longitude values are valid. For example:\n",
        "    - **Dallas, TX:** Latitude `32.7767`, Longitude `-96.7970`\n",
        "    - **New York City, NY:** Latitude `40.7128`, Longitude `-74.0060`\n",
        "    \"\"\")\n",
        "\n",
        "# Step 9: Launch the Gradio interface\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "WktPScqOY1D9",
        "outputId": "56b51f34-7809-4d41-8e09-76d652741a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "        Hugging Face token (HF_TOKEN) not found.\n",
            "        Proceeding without authentication may lead to rate limiting.\n",
            "        To set the token, add it to environment variables or set it directly in the notebook.\n",
            "        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ee270586f0973a91a8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee270586f0973a91a8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "############### NOAA V2\n",
        "\n",
        "# Text summarization\n",
        "\n",
        "# facebook/bart-large-cnn\n",
        "\n",
        "# Raw data + Raw summary + Temperature plot\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional, Tuple, List\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import requests\n",
        "from cachetools import TTLCache, cached\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ---------------------- Configuration ----------------------\n",
        "\n",
        "# Constants and configuration variables\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "CACHE_TTL = 600  # Cache Time-To-Live in seconds (e.g., 10 minutes)\n",
        "FORECAST_DAYS = 3  # Number of days to include in the summary\n",
        "\n",
        "# Optional: Hugging Face Token for authenticated access\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Ensure this environment variable is set if you have a token\n",
        "\n",
        "# ---------------------- Logging Setup ----------------------\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"\n",
        "    Configures the logging settings.\n",
        "    \"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "setup_logging()\n",
        "\n",
        "# ---------------------- Cache Setup ----------------------\n",
        "\n",
        "# Initialize a TTL cache with a maximum size of 100 items and TTL of CACHE_TTL seconds\n",
        "forecast_cache = TTLCache(maxsize=100, ttl=CACHE_TTL)\n",
        "\n",
        "# ---------------------- NOAA Data Fetcher ----------------------\n",
        "\n",
        "class NOAADataFetcher:\n",
        "    \"\"\"\n",
        "    Fetches weather forecast data from NOAA's National Weather Service (NWS) API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, user_agent: str):\n",
        "        self.user_agent = user_agent\n",
        "        self.headers = {'User-Agent': self.user_agent}\n",
        "        self.endpoint_template = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "\n",
        "    @cached(cache=forecast_cache)\n",
        "    def fetch_forecast(self, latitude: float, longitude: float) -> Optional[dict]:\n",
        "        \"\"\"\n",
        "        Fetches the weather forecast data for the given latitude and longitude.\n",
        "\n",
        "        Args:\n",
        "            latitude (float): Latitude of the location.\n",
        "            longitude (float): Longitude of the location.\n",
        "\n",
        "        Returns:\n",
        "            dict: JSON response containing forecast data, or None if failed.\n",
        "        \"\"\"\n",
        "        endpoint = self.endpoint_template.format(latitude=latitude, longitude=longitude)\n",
        "        try:\n",
        "            logging.info(f\"Fetching metadata from NOAA NWS API for lat: {latitude}, lon: {longitude}.\")\n",
        "            response = requests.get(endpoint, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            logging.debug(f\"Metadata Response: {json.dumps(data, indent=2)}\")\n",
        "\n",
        "            # Extract the forecast URL\n",
        "            forecast_url = data['properties']['forecast']\n",
        "            logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "            forecast_response = requests.get(forecast_url, headers=self.headers, timeout=10)\n",
        "            forecast_response.raise_for_status()\n",
        "            forecast_data = forecast_response.json()\n",
        "            logging.debug(f\"Forecast Response: {json.dumps(forecast_data, indent=2)}\")\n",
        "\n",
        "            return forecast_data\n",
        "\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            logging.error(f\"HTTP error occurred: {http_err}\")\n",
        "        except requests.exceptions.RequestException as req_err:\n",
        "            logging.error(f\"Request exception: {req_err}\")\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error: {key_err}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# ---------------------- Weather Data Parser ----------------------\n",
        "\n",
        "class WeatherDataParser:\n",
        "    \"\"\"\n",
        "    Parses and processes raw weather forecast data from NOAA's NWS API.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_forecast(self, forecast_data: dict, days: int = 3) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parses forecast data and constructs descriptive paragraphs.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "            days (int): Number of days to include in the summary.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs for each forecast period.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Parsing weather data.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            filtered_periods = self.filter_forecast_periods(periods, days)\n",
        "            paragraphs = self.construct_paragraphs(filtered_periods)\n",
        "            logging.debug(f\"Full Paragraph: {' '.join(paragraphs)}\")\n",
        "            return paragraphs\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while parsing weather data: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error parsing weather data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def filter_forecast_periods(self, periods: List[dict], days: int) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Filters forecast periods to include only the specified number of days.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "            days (int): Number of days to include.\n",
        "\n",
        "        Returns:\n",
        "            list: Filtered list of forecast periods.\n",
        "        \"\"\"\n",
        "        filtered = []\n",
        "        current_day = None\n",
        "        for period in periods:\n",
        "            day = period['startTime'][:10]  # Extract YYYY-MM-DD\n",
        "            if day != current_day:\n",
        "                current_day = day\n",
        "                filtered.append(period)\n",
        "                if len(filtered) >= days * 2:  # Day and Night for each day\n",
        "                    break\n",
        "        logging.info(f\"Filtered down to {len(filtered)} periods for summarization.\")\n",
        "        return filtered\n",
        "\n",
        "    def construct_paragraphs(self, periods: List[dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Constructs descriptive paragraphs from forecast periods.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs.\n",
        "        \"\"\"\n",
        "        paragraphs = []\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(f\"Parsed forecast for {name}: {forecast_paragraph}\")\n",
        "        return paragraphs\n",
        "\n",
        "# ---------------------- Weather Summarizer ----------------------\n",
        "\n",
        "class WeatherSummarizer:\n",
        "    \"\"\"\n",
        "    Generates concise summaries from parsed weather forecast data using a summarization model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"facebook/bart-large-cnn\", device: int = -1):\n",
        "        \"\"\"\n",
        "        Initializes the summarizer with the specified model and device.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the Hugging Face model to use.\n",
        "            device (int): Device to run the model on (-1 for CPU, 0 for GPU).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Loading spaCy language model for summarization.\")\n",
        "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
        "            logging.info(\"spaCy model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load spaCy model: {e}\")\n",
        "            raise\n",
        "\n",
        "        try:\n",
        "            logging.info(f\"Loading BART summarization pipeline with model '{model_name}'.\")\n",
        "            self.summarizer = pipeline(\"summarization\", model=model_name, device=device)\n",
        "            logging.info(\"BART summarization pipeline loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load BART model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize(self, paragraphs: List[str], max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the provided paragraphs.\n",
        "\n",
        "        Args:\n",
        "            paragraphs (list): List of descriptive paragraphs.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary using BART model.\")\n",
        "            full_text = \" \".join(paragraphs)\n",
        "            summary = self.summarizer(\n",
        "                full_text,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Visualization ----------------------\n",
        "\n",
        "def plot_temperatures(paragraphs: List[str]) -> Optional[plt.Figure]:\n",
        "    \"\"\"\n",
        "    Generates a temperature trend plot from the forecast paragraphs.\n",
        "\n",
        "    Args:\n",
        "        paragraphs (list): List of descriptive paragraphs.\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: Generated plot figure, or None if no data.\n",
        "    \"\"\"\n",
        "    temperatures = []\n",
        "    periods = []\n",
        "    for p in paragraphs:\n",
        "        try:\n",
        "            temp_start = p.find(\"temperature will be \") + len(\"temperature will be \")\n",
        "            temp_end = p.find(\"°\", temp_start)\n",
        "            temp = int(p[temp_start:temp_end])\n",
        "            name = p.split(\":\")[0]\n",
        "            temperatures.append(temp)\n",
        "            periods.append(name)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not temperatures:\n",
        "        logging.warning(\"No temperature data available for plotting.\")\n",
        "        return None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(periods, temperatures, marker='o', linestyle='-', color='b')\n",
        "    ax.set_title('Temperature Over Time')\n",
        "    ax.set_xlabel('Period')\n",
        "    ax.set_ylabel('Temperature (°F)')\n",
        "    ax.grid(True)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------- Input Validation ----------------------\n",
        "\n",
        "def validate_coordinates(latitude: float, longitude: float) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Validates the latitude and longitude values.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude value.\n",
        "        longitude (float): Longitude value.\n",
        "\n",
        "    Returns:\n",
        "        str: Error message if invalid, else None.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    if not (-90 <= latitude <= 90):\n",
        "        errors.append(\"Latitude must be between -90 and 90.\")\n",
        "    if not (-180 <= longitude <= 180):\n",
        "        errors.append(\"Longitude must be between -180 and 180.\")\n",
        "    if errors:\n",
        "        return \" \".join(errors)\n",
        "    return None\n",
        "\n",
        "# ---------------------- Gradio Interface Function ----------------------\n",
        "\n",
        "def weather_gradio_interface(latitude: float, longitude: float, show_plot: bool) -> Tuple[str, str, Optional[plt.Figure]]:\n",
        "    \"\"\"\n",
        "    Gradio interface function to fetch, parse, and summarize weather data.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude input by the user.\n",
        "        longitude (float): Longitude input by the user.\n",
        "        show_plot (bool): Whether to display the temperature trend plot.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Raw data (formatted JSON), summary, and plot (if enabled).\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    validation_error = validate_coordinates(latitude, longitude)\n",
        "    if validation_error:\n",
        "        logging.error(f\"Input validation failed: {validation_error}\")\n",
        "        return validation_error, \"Unable to generate summary due to invalid inputs.\", None\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = NOAADataFetcher(user_agent=USER_AGENT)\n",
        "    parser = WeatherDataParser()\n",
        "    summarizer = WeatherSummarizer(model_name=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    try:\n",
        "        # Fetch data\n",
        "        forecast_data = fetcher.fetch_forecast(latitude, longitude)\n",
        "        if not forecast_data:\n",
        "            logging.error(\"No forecast data retrieved.\")\n",
        "            return \"No forecast data retrieved.\", \"Unable to generate summary.\", None\n",
        "\n",
        "        # Parse data\n",
        "        paragraphs = parser.parse_forecast(forecast_data, days=FORECAST_DAYS)\n",
        "        if not paragraphs:\n",
        "            logging.error(\"No weather information available to summarize.\")\n",
        "            return \"No weather information available to summarize.\", \"Unable to generate summary.\", None\n",
        "\n",
        "        # Summarize\n",
        "        summary = summarizer.summarize(paragraphs)\n",
        "\n",
        "        # Prepare raw data\n",
        "        raw_data = json.dumps(forecast_data, indent=2)\n",
        "\n",
        "        # Plot temperatures if requested\n",
        "        plot = plot_temperatures(paragraphs) if show_plot else None\n",
        "\n",
        "        return raw_data, summary, plot\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"Error in Gradio interface: {e}\")\n",
        "        return f\"An error occurred: {e}\", \"Unable to generate summary.\", None\n",
        "\n",
        "# ---------------------- Main Execution ----------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure Hugging Face Token is set if available\n",
        "    if HF_TOKEN:\n",
        "        os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "        logging.info(\"Hugging Face token found and set.\")\n",
        "    else:\n",
        "        logging.warning(\"\"\"\n",
        "        Hugging Face token (HF_TOKEN) not found.\n",
        "        Proceeding without authentication may lead to rate limiting.\n",
        "        To set the token, add it to environment variables or set it directly in the notebook.\n",
        "        \"\"\")\n",
        "\n",
        "    # Determine device for transformers pipeline\n",
        "    import torch\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    if device == 0:\n",
        "        logging.info(\"Using GPU for transformers pipeline.\")\n",
        "    else:\n",
        "        logging.info(\"GPU not available. Using CPU for transformers pipeline.\")\n",
        "\n",
        "    # Launch Gradio Interface\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Weather Summarizer\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Enter the **latitude** and **longitude** of a location to retrieve a summarized weather forecast.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            latitude_input = gr.Number(label=\"Latitude\", value=32.7767)\n",
        "            longitude_input = gr.Number(label=\"Longitude\", value=-96.7970)\n",
        "\n",
        "        show_plot = gr.Checkbox(label=\"Show Temperature Trend Plot\", value=True)\n",
        "\n",
        "        submit_button = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Tab(\"Raw Data\"):\n",
        "            raw_output = gr.Textbox(label=\"Raw NOAA API Response\", lines=20, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Raw Summary\"):\n",
        "            summary_output = gr.Textbox(label=\"Summarized Weather Forecast\", lines=10, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Temperature Plot\"):\n",
        "            temperature_plot = gr.Plot(label=\"Temperature Trend\")\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=weather_gradio_interface,\n",
        "            inputs=[latitude_input, longitude_input, show_plot],\n",
        "            outputs=[raw_output, summary_output, temperature_plot]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **Note:** Ensure that the latitude and longitude values are valid. For example:\n",
        "        - **Dallas, TX:** Latitude `32.7767`, Longitude `-96.7970`\n",
        "        - **New York City, NY:** Latitude `40.7128`, Longitude `-74.0060`\n",
        "        \"\"\")\n",
        "\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "s7M-XVTCe5FT",
        "outputId": "1407beea-9257-4fea-8879-2e0018157ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "        Hugging Face token (HF_TOKEN) not found.\n",
            "        Proceeding without authentication may lead to rate limiting.\n",
            "        To set the token, add it to environment variables or set it directly in the notebook.\n",
            "        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ead7474b401e30dae8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ead7474b401e30dae8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "############## NOAA V3\n",
        "\n",
        "# Text summarization\n",
        "\n",
        "# facebook/bart-large-cnn\n",
        "\n",
        "# NOAA Raw Response + Sumarize weather forecast\n",
        "\n",
        "# Detailed forecast + detailed summary\n",
        "\n",
        "\n",
        "\n",
        "############### NOAA V2\n",
        "\n",
        "# weather_summarizer.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import requests\n",
        "from cachetools import TTLCache, cached\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ---------------------- Configuration ----------------------\n",
        "\n",
        "# Constants and configuration variables\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "CACHE_TTL = 600  # Cache Time-To-Live in seconds (e.g., 10 minutes)\n",
        "FORECAST_DAYS = 3  # Number of days to include in the summary\n",
        "\n",
        "# Optional: Hugging Face Token for authenticated access\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Ensure this environment variable is set if you have a token\n",
        "\n",
        "# ---------------------- Logging Setup ----------------------\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"\n",
        "    Configures the logging settings.\n",
        "    \"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "setup_logging()\n",
        "\n",
        "# ---------------------- Cache Setup ----------------------\n",
        "\n",
        "# Initialize a TTL cache with a maximum size of 100 items and TTL of CACHE_TTL seconds\n",
        "forecast_cache = TTLCache(maxsize=100, ttl=CACHE_TTL)\n",
        "\n",
        "# ---------------------- NOAA Data Fetcher ----------------------\n",
        "\n",
        "class NOAADataFetcher:\n",
        "    \"\"\"\n",
        "    Fetches weather forecast data from NOAA's National Weather Service (NWS) API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, user_agent: str):\n",
        "        self.user_agent = user_agent\n",
        "        self.headers = {'User-Agent': self.user_agent}\n",
        "        self.endpoint_template = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "\n",
        "    @cached(cache=forecast_cache)\n",
        "    def fetch_forecast(self, latitude: float, longitude: float) -> Optional[dict]:\n",
        "        \"\"\"\n",
        "        Fetches the weather forecast data for the given latitude and longitude.\n",
        "\n",
        "        Args:\n",
        "            latitude (float): Latitude of the location.\n",
        "            longitude (float): Longitude of the location.\n",
        "\n",
        "        Returns:\n",
        "            dict: JSON response containing forecast data, or None if failed.\n",
        "        \"\"\"\n",
        "        endpoint = self.endpoint_template.format(latitude=latitude, longitude=longitude)\n",
        "        try:\n",
        "            logging.info(f\"Fetching metadata from NOAA NWS API for lat: {latitude}, lon: {longitude}.\")\n",
        "            response = requests.get(endpoint, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            logging.debug(f\"Metadata Response: {json.dumps(data, indent=2)}\")\n",
        "\n",
        "            # Extract the forecast URL\n",
        "            forecast_url = data['properties']['forecast']\n",
        "            logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "            forecast_response = requests.get(forecast_url, headers=self.headers, timeout=10)\n",
        "            forecast_response.raise_for_status()\n",
        "            forecast_data = forecast_response.json()\n",
        "            logging.debug(f\"Forecast Response: {json.dumps(forecast_data, indent=2)}\")\n",
        "\n",
        "            return forecast_data\n",
        "\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            logging.error(f\"HTTP error occurred: {http_err}\")\n",
        "        except requests.exceptions.RequestException as req_err:\n",
        "            logging.error(f\"Request exception: {req_err}\")\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error: {key_err}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# ---------------------- Weather Data Parser ----------------------\n",
        "\n",
        "class WeatherDataParser:\n",
        "    \"\"\"\n",
        "    Parses and processes raw weather forecast data from NOAA's NWS API.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_forecast(self, forecast_data: dict, days: int = 3) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parses forecast data and constructs descriptive paragraphs.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "            days (int): Number of days to include in the summary.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs for each forecast period.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Parsing weather data.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            filtered_periods = self.filter_forecast_periods(periods, days)\n",
        "            paragraphs = self.construct_paragraphs(filtered_periods)\n",
        "            logging.debug(f\"Full Paragraph: {' '.join(paragraphs)}\")\n",
        "            return paragraphs\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while parsing weather data: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error parsing weather data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def filter_forecast_periods(self, periods: List[dict], days: int) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Filters forecast periods to include only the specified number of days.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "            days (int): Number of days to include.\n",
        "\n",
        "        Returns:\n",
        "            list: Filtered list of forecast periods.\n",
        "        \"\"\"\n",
        "        filtered = []\n",
        "        current_day = None\n",
        "        for period in periods:\n",
        "            day = period['startTime'][:10]  # Extract YYYY-MM-DD\n",
        "            if day != current_day:\n",
        "                current_day = day\n",
        "                filtered.append(period)\n",
        "                if len(filtered) >= days * 2:  # Day and Night for each day\n",
        "                    break\n",
        "        logging.info(f\"Filtered down to {len(filtered)} periods for summarization.\")\n",
        "        return filtered\n",
        "\n",
        "    def construct_paragraphs(self, periods: List[dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Constructs descriptive paragraphs from forecast periods.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs.\n",
        "        \"\"\"\n",
        "        paragraphs = []\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(f\"Parsed forecast for {name}: {forecast_paragraph}\")\n",
        "        return paragraphs\n",
        "\n",
        "    ### New: Extract and Merge detailedForecasts\n",
        "\n",
        "    def extract_detailed_forecasts(self, forecast_data: dict) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Extracts the 'number' and 'detailedForecast' from each forecast period.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "\n",
        "        Returns:\n",
        "            list: List of dictionaries containing 'number' and 'detailedForecast'.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Extracting detailed forecasts.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            detailed_forecasts = []\n",
        "            for period in periods:\n",
        "                number = period.get('number')\n",
        "                detailed_forecast = period.get('detailedForecast', '')\n",
        "                if number is not None:\n",
        "                    detailed_forecasts.append({\n",
        "                        \"number\": number,\n",
        "                        \"detailedForecast\": detailed_forecast\n",
        "                    })\n",
        "            logging.debug(f\"Extracted Detailed Forecasts: {detailed_forecasts}\")\n",
        "            return detailed_forecasts\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while extracting detailed forecasts: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting detailed forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def merge_detailed_forecasts(self, detailed_forecasts: List[Dict[str, str]]) -> str:\n",
        "        \"\"\"\n",
        "        Merges the list of detailed forecasts into a structured JSON string.\n",
        "\n",
        "        Args:\n",
        "            detailed_forecasts (list): List of dictionaries with 'number' and 'detailedForecast'.\n",
        "\n",
        "        Returns:\n",
        "            str: Merged JSON string.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Merging detailed forecasts into structured JSON.\")\n",
        "            merged_content = \"\"\n",
        "            for forecast in detailed_forecasts:\n",
        "                merged_content += f'\"number\": {forecast[\"number\"]}\\n\"detailedForecast\": \"{forecast[\"detailedForecast\"]}\"\\n'\n",
        "            logging.debug(f\"Merged Content: {merged_content}\")\n",
        "            return merged_content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error merging detailed forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Weather Summarizer ----------------------\n",
        "\n",
        "class WeatherSummarizer:\n",
        "    \"\"\"\n",
        "    Generates concise summaries from parsed weather forecast data using a summarization model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"facebook/bart-large-cnn\", device: int = -1):\n",
        "        \"\"\"\n",
        "        Initializes the summarizer with the specified model and device.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the Hugging Face model to use.\n",
        "            device (int): Device to run the model on (-1 for CPU, 0 for GPU).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Loading spaCy language model for summarization.\")\n",
        "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
        "            logging.info(\"spaCy model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load spaCy model: {e}\")\n",
        "            raise\n",
        "\n",
        "        try:\n",
        "            logging.info(f\"Loading BART summarization pipeline with model '{model_name}'.\")\n",
        "            self.summarizer = pipeline(\"summarization\", model=model_name, device=device)\n",
        "            logging.info(\"BART summarization pipeline loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load BART model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize(self, paragraphs: List[str], max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the provided paragraphs.\n",
        "\n",
        "        Args:\n",
        "            paragraphs (list): List of descriptive paragraphs.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary using BART model.\")\n",
        "            full_text = \" \".join(paragraphs)\n",
        "            summary = self.summarizer(\n",
        "                full_text,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "    ### New: Summarize Merged Detailed Forecasts\n",
        "\n",
        "    def summarize_merged_forecast(self, merged_content: str, max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the merged detailed forecasts.\n",
        "\n",
        "        Args:\n",
        "            merged_content (str): Merged detailed forecasts as a single string.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary for merged detailed forecasts.\")\n",
        "            # Process the merged content with spaCy\n",
        "            doc = self.nlp(merged_content)\n",
        "            sentences = [sent.text for sent in doc.sents]\n",
        "            paragraph = \" \".join(sentences)\n",
        "            logging.debug(f\"Processed Paragraph for Summarization: {paragraph}\")\n",
        "\n",
        "            # Generate summary\n",
        "            summary = self.summarizer(\n",
        "                paragraph,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Merged summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during merged summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Visualization ----------------------\n",
        "\n",
        "def plot_temperatures(paragraphs: List[str]) -> Optional[plt.Figure]:\n",
        "    \"\"\"\n",
        "    Generates a temperature trend plot from the forecast paragraphs.\n",
        "\n",
        "    Args:\n",
        "        paragraphs (list): List of descriptive paragraphs.\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: Generated plot figure, or None if no data.\n",
        "    \"\"\"\n",
        "    temperatures = []\n",
        "    periods = []\n",
        "    for p in paragraphs:\n",
        "        try:\n",
        "            temp_start = p.find(\"temperature will be \") + len(\"temperature will be \")\n",
        "            temp_end = p.find(\"°\", temp_start)\n",
        "            temp = int(p[temp_start:temp_end])\n",
        "            name = p.split(\":\")[0]\n",
        "            temperatures.append(temp)\n",
        "            periods.append(name)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not temperatures:\n",
        "        logging.warning(\"No temperature data available for plotting.\")\n",
        "        return None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(periods, temperatures, marker='o', linestyle='-', color='b')\n",
        "    ax.set_title('Temperature Over Time')\n",
        "    ax.set_xlabel('Period')\n",
        "    ax.set_ylabel('Temperature (°F)')\n",
        "    ax.grid(True)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------- Input Validation ----------------------\n",
        "\n",
        "def validate_coordinates(latitude: float, longitude: float) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Validates the latitude and longitude values.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude value.\n",
        "        longitude (float): Longitude value.\n",
        "\n",
        "    Returns:\n",
        "        str: Error message if invalid, else None.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    if not (-90 <= latitude <= 90):\n",
        "        errors.append(\"Latitude must be between -90 and 90.\")\n",
        "    if not (-180 <= longitude <= 180):\n",
        "        errors.append(\"Longitude must be between -180 and 180.\")\n",
        "    if errors:\n",
        "        return \" \".join(errors)\n",
        "    return None\n",
        "\n",
        "# ---------------------- Gradio Interface Function ----------------------\n",
        "\n",
        "def weather_gradio_interface(latitude: float, longitude: float, show_plot: bool) -> Tuple[str, str, Optional[plt.Figure], str, str]:\n",
        "    \"\"\"\n",
        "    Gradio interface function to fetch, parse, and summarize weather data.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude input by the user.\n",
        "        longitude (float): Longitude input by the user.\n",
        "        show_plot (bool): Whether to display the temperature trend plot.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Raw data (formatted JSON), summary, plot (if enabled), merged detailed forecasts, merged summary.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    validation_error = validate_coordinates(latitude, longitude)\n",
        "    if validation_error:\n",
        "        logging.error(f\"Input validation failed: {validation_error}\")\n",
        "        return validation_error, \"Unable to generate summary due to invalid inputs.\", None, \"\", \"\"\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = NOAADataFetcher(user_agent=USER_AGENT)\n",
        "    parser = WeatherDataParser()\n",
        "    summarizer = WeatherSummarizer(model_name=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    try:\n",
        "        # Fetch data\n",
        "        forecast_data = fetcher.fetch_forecast(latitude, longitude)\n",
        "        if not forecast_data:\n",
        "            logging.error(\"No forecast data retrieved.\")\n",
        "            return \"No forecast data retrieved.\", \"Unable to generate summary.\", None, \"\", \"\"\n",
        "\n",
        "        # Parse data\n",
        "        paragraphs = parser.parse_forecast(forecast_data, days=FORECAST_DAYS)\n",
        "        if not paragraphs:\n",
        "            logging.error(\"No weather information available to summarize.\")\n",
        "            return \"No weather information available to summarize.\", \"Unable to generate summary.\", None, \"\", \"\"\n",
        "\n",
        "        # Summarize\n",
        "        summary = summarizer.summarize(paragraphs)\n",
        "\n",
        "        # Prepare raw data\n",
        "        raw_data = json.dumps(forecast_data, indent=2)\n",
        "\n",
        "        # Plot temperatures if requested\n",
        "        plot = plot_temperatures(paragraphs) if show_plot else None\n",
        "\n",
        "        ### New: Extract and Merge Detailed Forecasts\n",
        "        detailed_forecasts = parser.extract_detailed_forecasts(forecast_data)\n",
        "        merged_detailed_forecasts = parser.merge_detailed_forecasts(detailed_forecasts)\n",
        "\n",
        "        # Summarize merged detailed forecasts\n",
        "        merged_summary = summarizer.summarize_merged_forecast(merged_detailed_forecasts)\n",
        "\n",
        "        return raw_data, summary, plot, merged_detailed_forecasts, merged_summary\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"Error in Gradio interface: {e}\")\n",
        "        return f\"An error occurred: {e}\", \"Unable to generate summary.\", None, \"\", \"\"\n",
        "\n",
        "# ---------------------- Main Execution ----------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure Hugging Face Token is set if available\n",
        "    if HF_TOKEN:\n",
        "        os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "        logging.info(\"Hugging Face token found and set.\")\n",
        "    else:\n",
        "        logging.warning(\"\"\"\n",
        "        Hugging Face token (HF_TOKEN) not found.\n",
        "        Proceeding without authentication may lead to rate limiting.\n",
        "        To set the token, add it to environment variables or set it directly in the notebook.\n",
        "        \"\"\")\n",
        "\n",
        "    # Determine device for transformers pipeline\n",
        "    import torch\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    if device == 0:\n",
        "        logging.info(\"Using GPU for transformers pipeline.\")\n",
        "    else:\n",
        "        logging.info(\"GPU not available. Using CPU for transformers pipeline.\")\n",
        "\n",
        "    # Launch Gradio Interface\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Weather Summarizer\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Enter the **latitude** and **longitude** of a location to retrieve a summarized weather forecast.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            latitude_input = gr.Number(label=\"Latitude\", value=32.7767)\n",
        "            longitude_input = gr.Number(label=\"Longitude\", value=-96.7970)\n",
        "\n",
        "        show_plot = gr.Checkbox(label=\"Show Temperature Trend Plot\", value=True)\n",
        "\n",
        "        submit_button = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Tab(\"Raw Data\"):\n",
        "            raw_output = gr.Textbox(label=\"Raw NOAA API Response\", lines=20, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Raw Summary\"):\n",
        "            summary_output = gr.Textbox(label=\"Summarized Weather Forecast\", lines=10, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Temperature Plot\"):\n",
        "            temperature_plot = gr.Plot(label=\"Temperature Trend\")\n",
        "\n",
        "        ### New: Additional Tabs for Merged Forecasts and Summary\n",
        "        with gr.Tab(\"Detailed Forecasts\"):\n",
        "            merged_forecast_output = gr.Textbox(label=\"Merged Detailed Forecasts\", lines=30, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Detailed Summary\"):\n",
        "            merged_summary_output = gr.Textbox(label=\"Summarized Merged Forecast\", lines=5, interactive=False)\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=weather_gradio_interface,\n",
        "            inputs=[latitude_input, longitude_input, show_plot],\n",
        "            outputs=[raw_output, summary_output, temperature_plot, merged_forecast_output, merged_summary_output]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **Note:** Ensure that the latitude and longitude values are valid. For example:\n",
        "        - **Dallas, TX:** Latitude `32.7767`, Longitude `-96.7970`\n",
        "        - **New York City, NY:** Latitude `40.7128`, Longitude `-74.0060`\n",
        "        \"\"\")\n",
        "\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "0ZmocP9Pf6-1",
        "outputId": "08de4bf6-69fb-41f0-84d8-72b097aa2fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "        Hugging Face token (HF_TOKEN) not found.\n",
            "        Proceeding without authentication may lead to rate limiting.\n",
            "        To set the token, add it to environment variables or set it directly in the notebook.\n",
            "        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9641ebe99d6c748d0d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9641ebe99d6c748d0d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "############## NOAA V4\n",
        "\n",
        "\n",
        "# Text summarization\n",
        "\n",
        "# facebook/bart-large-cnn\n",
        "\n",
        "# NOAA Raw Response + Sumarize weather forecast\n",
        "\n",
        "# Detailed forecast + detailed summary\n",
        "\n",
        "# Short forecat + short summary\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import requests\n",
        "from cachetools import TTLCache, cached\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ---------------------- Configuration ----------------------\n",
        "\n",
        "# Constants and configuration variables\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "CACHE_TTL = 600  # Cache Time-To-Live in seconds (e.g., 10 minutes)\n",
        "FORECAST_DAYS = 3  # Number of days to include in the summary\n",
        "\n",
        "# Optional: Hugging Face Token for authenticated access\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Ensure this environment variable is set if you have a token\n",
        "\n",
        "# ---------------------- Logging Setup ----------------------\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"\n",
        "    Configures the logging settings.\n",
        "    \"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "setup_logging()\n",
        "\n",
        "# ---------------------- Cache Setup ----------------------\n",
        "\n",
        "# Initialize a TTL cache with a maximum size of 100 items and TTL of CACHE_TTL seconds\n",
        "forecast_cache = TTLCache(maxsize=100, ttl=CACHE_TTL)\n",
        "\n",
        "# ---------------------- NOAA Data Fetcher ----------------------\n",
        "\n",
        "class NOAADataFetcher:\n",
        "    \"\"\"\n",
        "    Fetches weather forecast data from NOAA's National Weather Service (NWS) API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, user_agent: str):\n",
        "        self.user_agent = user_agent\n",
        "        self.headers = {'User-Agent': self.user_agent}\n",
        "        self.endpoint_template = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "\n",
        "    @cached(cache=forecast_cache)\n",
        "    def fetch_forecast(self, latitude: float, longitude: float) -> Optional[dict]:\n",
        "        \"\"\"\n",
        "        Fetches the weather forecast data for the given latitude and longitude.\n",
        "\n",
        "        Args:\n",
        "            latitude (float): Latitude of the location.\n",
        "            longitude (float): Longitude of the location.\n",
        "\n",
        "        Returns:\n",
        "            dict: JSON response containing forecast data, or None if failed.\n",
        "        \"\"\"\n",
        "        endpoint = self.endpoint_template.format(latitude=latitude, longitude=longitude)\n",
        "        try:\n",
        "            logging.info(f\"Fetching metadata from NOAA NWS API for lat: {latitude}, lon: {longitude}.\")\n",
        "            response = requests.get(endpoint, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            logging.debug(f\"Metadata Response: {json.dumps(data, indent=2)}\")\n",
        "\n",
        "            # Extract the forecast URL\n",
        "            forecast_url = data['properties']['forecast']\n",
        "            logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "            forecast_response = requests.get(forecast_url, headers=self.headers, timeout=10)\n",
        "            forecast_response.raise_for_status()\n",
        "            forecast_data = forecast_response.json()\n",
        "            logging.debug(f\"Forecast Response: {json.dumps(forecast_data, indent=2)}\")\n",
        "\n",
        "            return forecast_data\n",
        "\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            logging.error(f\"HTTP error occurred: {http_err}\")\n",
        "        except requests.exceptions.RequestException as req_err:\n",
        "            logging.error(f\"Request exception: {req_err}\")\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error: {key_err}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# ---------------------- Weather Data Parser ----------------------\n",
        "\n",
        "class WeatherDataParser:\n",
        "    \"\"\"\n",
        "    Parses and processes raw weather forecast data from NOAA's NWS API.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_forecast(self, forecast_data: dict, days: int = 3) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parses forecast data and constructs descriptive paragraphs.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "            days (int): Number of days to include in the summary.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs for each forecast period.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Parsing weather data.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            filtered_periods = self.filter_forecast_periods(periods, days)\n",
        "            paragraphs = self.construct_paragraphs(filtered_periods)\n",
        "            logging.debug(f\"Full Paragraph: {' '.join(paragraphs)}\")\n",
        "            return paragraphs\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while parsing weather data: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error parsing weather data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def filter_forecast_periods(self, periods: List[dict], days: int) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Filters forecast periods to include only the specified number of days.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "            days (int): Number of days to include.\n",
        "\n",
        "        Returns:\n",
        "            list: Filtered list of forecast periods.\n",
        "        \"\"\"\n",
        "        filtered = []\n",
        "        current_day = None\n",
        "        for period in periods:\n",
        "            day = period['startTime'][:10]  # Extract YYYY-MM-DD\n",
        "            if day != current_day:\n",
        "                current_day = day\n",
        "                filtered.append(period)\n",
        "                if len(filtered) >= days * 2:  # Day and Night for each day\n",
        "                    break\n",
        "        logging.info(f\"Filtered down to {len(filtered)} periods for summarization.\")\n",
        "        return filtered\n",
        "\n",
        "    def construct_paragraphs(self, periods: List[dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Constructs descriptive paragraphs from forecast periods.\n",
        "\n",
        "        Args:\n",
        "            periods (list): List of forecast periods.\n",
        "\n",
        "        Returns:\n",
        "            list: List of descriptive paragraphs.\n",
        "        \"\"\"\n",
        "        paragraphs = []\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(f\"Parsed forecast for {name}: {forecast_paragraph}\")\n",
        "        return paragraphs\n",
        "\n",
        "    ### New: Extract and Merge detailedForecasts\n",
        "\n",
        "    def extract_detailed_forecasts(self, forecast_data: dict) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Extracts the 'number' and 'detailedForecast' from each forecast period.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "\n",
        "        Returns:\n",
        "            list: List of dictionaries containing 'number' and 'detailedForecast'.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Extracting detailed forecasts.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            detailed_forecasts = []\n",
        "            for period in periods:\n",
        "                number = period.get('number')\n",
        "                detailed_forecast = period.get('detailedForecast', '')\n",
        "                if number is not None:\n",
        "                    detailed_forecasts.append({\n",
        "                        \"number\": number,\n",
        "                        \"detailedForecast\": detailed_forecast\n",
        "                    })\n",
        "            logging.debug(f\"Extracted Detailed Forecasts: {detailed_forecasts}\")\n",
        "            return detailed_forecasts\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while extracting detailed forecasts: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting detailed forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def merge_detailed_forecasts(self, detailed_forecasts: List[Dict[str, str]]) -> str:\n",
        "        \"\"\"\n",
        "        Merges the list of detailed forecasts into a structured string.\n",
        "\n",
        "        Args:\n",
        "            detailed_forecasts (list): List of dictionaries with 'number' and 'detailedForecast'.\n",
        "\n",
        "        Returns:\n",
        "            str: Merged structured string.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Merging detailed forecasts into structured format.\")\n",
        "            merged_content = \"\"\n",
        "            for forecast in detailed_forecasts:\n",
        "                merged_content += f'\"number\": {forecast[\"number\"]}\\n\"detailedForecast\": \"{forecast[\"detailedForecast\"]}\"\\n'\n",
        "            logging.debug(f\"Merged Detailed Forecasts Content:\\n{merged_content}\")\n",
        "            return merged_content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error merging detailed forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "    ### New: Extract and Merge shortForecasts\n",
        "\n",
        "    def extract_short_forecasts(self, forecast_data: dict) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Extracts the 'number' and 'shortForecast' from each forecast period.\n",
        "\n",
        "        Args:\n",
        "            forecast_data (dict): JSON data from NOAA NWS API.\n",
        "\n",
        "        Returns:\n",
        "            list: List of dictionaries containing 'number' and 'shortForecast'.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Extracting short forecasts.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            short_forecasts = []\n",
        "            for period in periods:\n",
        "                number = period.get('number')\n",
        "                short_forecast = period.get('shortForecast', '')\n",
        "                if number is not None:\n",
        "                    short_forecasts.append({\n",
        "                        \"number\": number,\n",
        "                        \"shortForecast\": short_forecast\n",
        "                    })\n",
        "            logging.debug(f\"Extracted Short Forecasts: {short_forecasts}\")\n",
        "            return short_forecasts\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while extracting short forecasts: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting short forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def merge_short_forecasts(self, short_forecasts: List[Dict[str, str]]) -> str:\n",
        "        \"\"\"\n",
        "        Merges the list of short forecasts into a structured string.\n",
        "\n",
        "        Args:\n",
        "            short_forecasts (list): List of dictionaries with 'number' and 'shortForecast'.\n",
        "\n",
        "        Returns:\n",
        "            str: Merged structured string.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Merging short forecasts into structured format.\")\n",
        "            merged_content = \"\"\n",
        "            for forecast in short_forecasts:\n",
        "                merged_content += f'\"number\": {forecast[\"number\"]}\\n\"shortForecast\": \"{forecast[\"shortForecast\"]}\"\\n'\n",
        "            logging.debug(f\"Merged Short Forecasts Content:\\n{merged_content}\")\n",
        "            return merged_content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error merging short forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Weather Summarizer ----------------------\n",
        "\n",
        "class WeatherSummarizer:\n",
        "    \"\"\"\n",
        "    Generates concise summaries from parsed weather forecast data using a summarization model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"facebook/bart-large-cnn\", device: int = -1):\n",
        "        \"\"\"\n",
        "        Initializes the summarizer with the specified model and device.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name of the Hugging Face model to use.\n",
        "            device (int): Device to run the model on (-1 for CPU, 0 for GPU).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Loading spaCy language model for summarization.\")\n",
        "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
        "            logging.info(\"spaCy model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load spaCy model: {e}\")\n",
        "            raise\n",
        "\n",
        "        try:\n",
        "            logging.info(f\"Loading BART summarization pipeline with model '{model_name}'.\")\n",
        "            self.summarizer = pipeline(\"summarization\", model=model_name, device=device)\n",
        "            logging.info(\"BART summarization pipeline loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load BART model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize(self, paragraphs: List[str], max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the provided paragraphs.\n",
        "\n",
        "        Args:\n",
        "            paragraphs (list): List of descriptive paragraphs.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary using BART model.\")\n",
        "            full_text = \" \".join(paragraphs)\n",
        "            summary = self.summarizer(\n",
        "                full_text,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "    ### New: Summarize Merged Detailed Forecasts\n",
        "\n",
        "    def summarize_merged_forecast(self, merged_content: str, max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the merged detailed forecasts.\n",
        "\n",
        "        Args:\n",
        "            merged_content (str): Merged detailed forecasts as a single string.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary for merged detailed forecasts.\")\n",
        "            # Process the merged content with spaCy\n",
        "            doc = self.nlp(merged_content)\n",
        "            sentences = [sent.text for sent in doc.sents]\n",
        "            paragraph = \" \".join(sentences)\n",
        "            logging.debug(f\"Processed Paragraph for Summarization: {paragraph}\")\n",
        "\n",
        "            # Generate summary\n",
        "            summary = self.summarizer(\n",
        "                paragraph,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Merged summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during merged summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "    ### New: Summarize Merged Short Forecasts\n",
        "\n",
        "    def summarize_merged_short_forecasts(self, merged_content: str, max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the merged short forecasts.\n",
        "\n",
        "        Args:\n",
        "            merged_content (str): Merged short forecasts as a single string.\n",
        "            max_length (int): Maximum length of the summary.\n",
        "            min_length (int): Minimum length of the summary.\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary for merged short forecasts.\")\n",
        "            # Process the merged content with spaCy\n",
        "            doc = self.nlp(merged_content)\n",
        "            sentences = [sent.text for sent in doc.sents]\n",
        "            paragraph = \" \".join(sentences)\n",
        "            logging.debug(f\"Processed Paragraph for Short Forecast Summarization: {paragraph}\")\n",
        "\n",
        "            # Generate summary\n",
        "            summary = self.summarizer(\n",
        "                paragraph,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=False\n",
        "            )\n",
        "            logging.info(\"Short forecasts summary generated successfully.\")\n",
        "            return summary[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during short forecasts summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Visualization ----------------------\n",
        "\n",
        "def plot_temperatures(paragraphs: List[str]) -> Optional[plt.Figure]:\n",
        "    \"\"\"\n",
        "    Generates a temperature trend plot from the forecast paragraphs.\n",
        "\n",
        "    Args:\n",
        "        paragraphs (list): List of descriptive paragraphs.\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure: Generated plot figure, or None if no data.\n",
        "    \"\"\"\n",
        "    temperatures = []\n",
        "    periods = []\n",
        "    for p in paragraphs:\n",
        "        try:\n",
        "            temp_start = p.find(\"temperature will be \") + len(\"temperature will be \")\n",
        "            temp_end = p.find(\"°\", temp_start)\n",
        "            temp = int(p[temp_start:temp_end])\n",
        "            name = p.split(\":\")[0]\n",
        "            temperatures.append(temp)\n",
        "            periods.append(name)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not temperatures:\n",
        "        logging.warning(\"No temperature data available for plotting.\")\n",
        "        return None\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(periods, temperatures, marker='o', linestyle='-', color='b')\n",
        "    ax.set_title('Temperature Over Time')\n",
        "    ax.set_xlabel('Period')\n",
        "    ax.set_ylabel('Temperature (°F)')\n",
        "    ax.grid(True)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------- Input Validation ----------------------\n",
        "\n",
        "def validate_coordinates(latitude: float, longitude: float) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Validates the latitude and longitude values.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude value.\n",
        "        longitude (float): Longitude value.\n",
        "\n",
        "    Returns:\n",
        "        str: Error message if invalid, else None.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    if not (-90 <= latitude <= 90):\n",
        "        errors.append(\"Latitude must be between -90 and 90.\")\n",
        "    if not (-180 <= longitude <= 180):\n",
        "        errors.append(\"Longitude must be between -180 and 180.\")\n",
        "    if errors:\n",
        "        return \" \".join(errors)\n",
        "    return None\n",
        "\n",
        "# ---------------------- Gradio Interface Function ----------------------\n",
        "\n",
        "def weather_gradio_interface(latitude: float, longitude: float, show_plot: bool) -> Tuple[str, str, Optional[plt.Figure], str, str, str, str]:\n",
        "    \"\"\"\n",
        "    Gradio interface function to fetch, parse, and summarize weather data.\n",
        "\n",
        "    Args:\n",
        "        latitude (float): Latitude input by the user.\n",
        "        longitude (float): Longitude input by the user.\n",
        "        show_plot (bool): Whether to display the temperature trend plot.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Raw data (formatted JSON), summary, plot (if enabled), merged detailed forecasts, merged summary, merged short forecasts, merged short summary.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    validation_error = validate_coordinates(latitude, longitude)\n",
        "    if validation_error:\n",
        "        logging.error(f\"Input validation failed: {validation_error}\")\n",
        "        return (\n",
        "            validation_error,\n",
        "            \"Unable to generate summary due to invalid inputs.\",\n",
        "            None,\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\"\n",
        "        )\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = NOAADataFetcher(user_agent=USER_AGENT)\n",
        "    parser = WeatherDataParser()\n",
        "    summarizer = WeatherSummarizer(model_name=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    try:\n",
        "        # Fetch data\n",
        "        forecast_data = fetcher.fetch_forecast(latitude, longitude)\n",
        "        if not forecast_data:\n",
        "            logging.error(\"No forecast data retrieved.\")\n",
        "            return (\n",
        "                \"No forecast data retrieved.\",\n",
        "                \"Unable to generate summary.\",\n",
        "                None,\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        # Parse data\n",
        "        paragraphs = parser.parse_forecast(forecast_data, days=FORECAST_DAYS)\n",
        "        if not paragraphs:\n",
        "            logging.error(\"No weather information available to summarize.\")\n",
        "            return (\n",
        "                \"No weather information available to summarize.\",\n",
        "                \"Unable to generate summary.\",\n",
        "                None,\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        # Summarize\n",
        "        summary = summarizer.summarize(paragraphs)\n",
        "\n",
        "        # Prepare raw data\n",
        "        raw_data = json.dumps(forecast_data, indent=2)\n",
        "\n",
        "        # Plot temperatures if requested\n",
        "        plot = plot_temperatures(paragraphs) if show_plot else None\n",
        "\n",
        "        ### Existing: Extract and Merge Detailed Forecasts\n",
        "        detailed_forecasts = parser.extract_detailed_forecasts(forecast_data)\n",
        "        merged_detailed_forecasts = parser.merge_detailed_forecasts(detailed_forecasts)\n",
        "\n",
        "        # Summarize merged detailed forecasts\n",
        "        merged_summary = summarizer.summarize_merged_forecast(merged_detailed_forecasts)\n",
        "\n",
        "        ### New: Extract and Merge Short Forecasts\n",
        "        short_forecasts = parser.extract_short_forecasts(forecast_data)\n",
        "        merged_short_forecasts = parser.merge_short_forecasts(short_forecasts)\n",
        "\n",
        "        # Summarize merged short forecasts\n",
        "        merged_short_summary = summarizer.summarize_merged_short_forecasts(merged_short_forecasts)\n",
        "\n",
        "        return (\n",
        "            raw_data,\n",
        "            summary,\n",
        "            plot,\n",
        "            merged_detailed_forecasts,\n",
        "            merged_summary,\n",
        "            merged_short_forecasts,\n",
        "            merged_short_summary\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"Error in Gradio interface: {e}\")\n",
        "        return (\n",
        "            f\"An error occurred: {e}\",\n",
        "            \"Unable to generate summary.\",\n",
        "            None,\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\"\n",
        "        )\n",
        "\n",
        "# ---------------------- Main Execution ----------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure Hugging Face Token is set if available\n",
        "    if HF_TOKEN:\n",
        "        os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "        logging.info(\"Hugging Face token found and set.\")\n",
        "    else:\n",
        "        logging.warning(\"\"\"\n",
        "        Hugging Face token (HF_TOKEN) not found.\n",
        "        Proceeding without authentication may lead to rate limiting.\n",
        "        To set the token, add it to environment variables or set it directly in the notebook.\n",
        "        \"\"\")\n",
        "\n",
        "    # Determine device for transformers pipeline\n",
        "    import torch\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    if device == 0:\n",
        "        logging.info(\"Using GPU for transformers pipeline.\")\n",
        "    else:\n",
        "        logging.info(\"GPU not available. Using CPU for transformers pipeline.\")\n",
        "\n",
        "    # Launch Gradio Interface\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Weather Summarizer\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Enter the **latitude** and **longitude** of a location to retrieve a summarized weather forecast.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            latitude_input = gr.Number(label=\"Latitude\", value=32.7767)\n",
        "            longitude_input = gr.Number(label=\"Longitude\", value=-96.7970)\n",
        "\n",
        "        show_plot = gr.Checkbox(label=\"Show Temperature Trend Plot\", value=True)\n",
        "\n",
        "        submit_button = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Tab(\"Raw Data\"):\n",
        "            raw_output = gr.Textbox(label=\"Raw NOAA API Response\", lines=20, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Raw Summary\"):\n",
        "            summary_output = gr.Textbox(label=\"Summarized Weather Forecast\", lines=10, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Temperature Plot\"):\n",
        "            temperature_plot = gr.Plot(label=\"Temperature Trend\")\n",
        "\n",
        "        with gr.Tab(\"Detailed Forecasts\"):\n",
        "            merged_forecast_output = gr.Textbox(label=\"Merged Detailed Forecasts\", lines=30, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Detailed Summary\"):\n",
        "            merged_summary_output = gr.Textbox(label=\"Summarized Merged Forecast\", lines=5, interactive=False)\n",
        "\n",
        "        ### New: Additional Tabs for Short Forecasts and Summary\n",
        "        with gr.Tab(\"Short Forecasts\"):\n",
        "            merged_short_forecast_output = gr.Textbox(label=\"Merged Short Forecasts\", lines=30, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Short Summary\"):\n",
        "            merged_short_summary_output = gr.Textbox(label=\"Summarized Short Forecasts\", lines=5, interactive=False)\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=weather_gradio_interface,\n",
        "            inputs=[latitude_input, longitude_input, show_plot],\n",
        "            outputs=[\n",
        "                raw_output,\n",
        "                summary_output,\n",
        "                temperature_plot,\n",
        "                merged_forecast_output,\n",
        "                merged_summary_output,\n",
        "                merged_short_forecast_output,\n",
        "                merged_short_summary_output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **Note:** Ensure that the latitude and longitude values are valid. For example:\n",
        "        - **Dallas, TX:** Latitude `32.7767`, Longitude `-96.7970`\n",
        "        - **New York City, NY:** Latitude `40.7128`, Longitude `-74.0060`\n",
        "        \"\"\")\n",
        "\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "5w23ulasmhpn",
        "outputId": "2e8dad73-4aaf-4e1d-d263-80c089571f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:\n",
            "        Hugging Face token (HF_TOKEN) not found.\n",
            "        Proceeding without authentication may lead to rate limiting.\n",
            "        \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bbabdbbb9434a95fa5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bbabdbbb9434a95fa5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#### NOAA API WEATHER FORECAST SUMMARIZATION\n",
        "# NOAA Raw Response + Sumarize weather forecast\n",
        "# Detailed forecast + detailed summary\n",
        "# Short forecat + short summary\n",
        "######## OpenaAI summarization\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "from datetime import datetime\n",
        "\n",
        "import requests\n",
        "from cachetools import TTLCache, cached\n",
        "import spacy\n",
        "import gradio as gr\n",
        "\n",
        "# NEW (OpenAI v1 migration)\n",
        "from openai import OpenAI\n",
        "# Hardcode your API key here\n",
        "client = OpenAI(\n",
        "    api_key=\"YOUR_OPENAI_API\"  # <-- Replace with your actual key\n",
        ")\n",
        "\n",
        "# ---------------------- Configuration ----------------------\n",
        "\n",
        "USER_AGENT = \"WeatherApp/1.0 (your.email@example.com)\"  # Replace with your actual email\n",
        "CACHE_TTL = 600  # Cache Time-To-Live in seconds (e.g., 10 minutes)\n",
        "FORECAST_DAYS = 14  # Number of days to include in the summary\n",
        "\n",
        "# Optional: Hugging Face Token for authenticated access\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Ensure this environment variable is set if you have a token\n",
        "\n",
        "# ---------------------- Logging Setup ----------------------\n",
        "\n",
        "def setup_logging():\n",
        "    \"\"\"\n",
        "    Configures the logging settings.\n",
        "    \"\"\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "setup_logging()\n",
        "\n",
        "# ---------------------- Cache Setup ----------------------\n",
        "\n",
        "# Initialize a TTL cache\n",
        "forecast_cache = TTLCache(maxsize=100, ttl=CACHE_TTL)\n",
        "\n",
        "# ---------------------- NOAA Data Fetcher ----------------------\n",
        "\n",
        "class NOAADataFetcher:\n",
        "    \"\"\"\n",
        "    Fetches weather forecast data from NOAA's National Weather Service (NWS) API.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, user_agent: str):\n",
        "        self.user_agent = user_agent\n",
        "        self.headers = {'User-Agent': self.user_agent}\n",
        "        self.endpoint_template = \"https://api.weather.gov/points/{latitude},{longitude}\"\n",
        "\n",
        "    @cached(cache=forecast_cache)\n",
        "    def fetch_forecast(self, latitude: float, longitude: float) -> Optional[dict]:\n",
        "        \"\"\"\n",
        "        Fetches the weather forecast data for the given latitude and longitude.\n",
        "        \"\"\"\n",
        "        endpoint = self.endpoint_template.format(latitude=latitude, longitude=longitude)\n",
        "        try:\n",
        "            logging.info(f\"Fetching metadata from NOAA NWS API for lat: {latitude}, lon: {longitude}.\")\n",
        "            response = requests.get(endpoint, headers=self.headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            logging.debug(f\"Metadata Response: {json.dumps(data, indent=2)}\")\n",
        "\n",
        "            # Extract the forecast URL\n",
        "            forecast_url = data['properties']['forecast']\n",
        "            logging.info(\"Fetching forecast data from NOAA NWS API.\")\n",
        "            forecast_response = requests.get(forecast_url, headers=self.headers, timeout=10)\n",
        "            forecast_response.raise_for_status()\n",
        "            forecast_data = forecast_response.json()\n",
        "            logging.debug(f\"Forecast Response: {json.dumps(forecast_data, indent=2)}\")\n",
        "\n",
        "            return forecast_data\n",
        "\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            logging.error(f\"HTTP error occurred: {http_err}\")\n",
        "        except requests.exceptions.RequestException as req_err:\n",
        "            logging.error(f\"Request exception: {req_err}\")\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error: {key_err}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "# ---------------------- Weather Data Parser ----------------------\n",
        "\n",
        "class WeatherDataParser:\n",
        "    \"\"\"\n",
        "    Parses and processes raw weather forecast data from NOAA's NWS API.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_forecast(self, forecast_data: dict, days: int = 14) -> List[str]:\n",
        "        \"\"\"\n",
        "        Parses forecast data and constructs descriptive paragraphs.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Parsing weather data.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            filtered_periods = self.filter_forecast_periods(periods, days)\n",
        "            paragraphs = self.construct_paragraphs(filtered_periods)\n",
        "            logging.debug(f\"Full Paragraph: {' '.join(paragraphs)}\")\n",
        "            return paragraphs\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while parsing weather data: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error parsing weather data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def filter_forecast_periods(self, periods: List[dict], days: int) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Filters forecast periods to include only the specified number of days.\n",
        "        \"\"\"\n",
        "        filtered = []\n",
        "        current_day = None\n",
        "        for period in periods:\n",
        "            day = period['startTime'][:10]  # Extract YYYY-MM-DD\n",
        "            if day != current_day:\n",
        "                current_day = day\n",
        "                filtered.append(period)\n",
        "                if len(filtered) >= days * 2:  # Day and Night for each day\n",
        "                    break\n",
        "        logging.info(f\"Filtered down to {len(filtered)} periods for summarization.\")\n",
        "        return filtered\n",
        "\n",
        "    def construct_paragraphs(self, periods: List[dict]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Constructs descriptive paragraphs from forecast periods.\n",
        "        \"\"\"\n",
        "        paragraphs = []\n",
        "        for period in periods:\n",
        "            name = period.get('name', 'N/A')\n",
        "            temperature = period.get('temperature', 'N/A')\n",
        "            temperature_unit = period.get('temperatureUnit', '')\n",
        "            wind_speed = period.get('windSpeed', 'N/A')\n",
        "            wind_direction = period.get('windDirection', 'N/A')\n",
        "            short_forecast = period.get('shortForecast', '')\n",
        "            detailed_forecast = period.get('detailedForecast', '')\n",
        "\n",
        "            forecast_paragraph = (\n",
        "                f\"{name}: The temperature will be {temperature}°{temperature_unit} \"\n",
        "                f\"with {short_forecast.lower()}. Winds are expected to be {wind_speed} \"\n",
        "                f\"from the {wind_direction.lower()}. {detailed_forecast}\"\n",
        "            )\n",
        "            paragraphs.append(forecast_paragraph)\n",
        "            logging.debug(f\"Parsed forecast for {name}: {forecast_paragraph}\")\n",
        "        return paragraphs\n",
        "\n",
        "    def extract_and_merge_detailed_forecasts(self, forecast_data: dict) -> str:\n",
        "        \"\"\"\n",
        "        Extracts 'number' and 'detailedForecast', transforms them, and concatenates into a paragraph.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Extracting and merging detailed forecasts.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            merged_content = \"\"\n",
        "            for period in periods:\n",
        "                number = period.get('number')\n",
        "                detailed_forecast = period.get('detailedForecast', '').strip()\n",
        "                if number is not None and detailed_forecast:\n",
        "                    day_forecast = f\"day {number} forecast suggests {detailed_forecast}\"\n",
        "                    merged_content += f\"{day_forecast} \"\n",
        "            merged_content = merged_content.strip()\n",
        "            logging.debug(f\"Merged Detailed Forecasts Paragraph: {merged_content}\")\n",
        "            return merged_content\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while extracting detailed forecasts: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting detailed forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "    def extract_and_merge_short_forecasts(self, forecast_data: dict) -> str:\n",
        "        \"\"\"\n",
        "        Extracts 'number' and 'shortForecast', transforms them, and concatenates into a paragraph.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Extracting and merging short forecasts.\")\n",
        "            periods = forecast_data['properties']['periods']\n",
        "            merged_content = \"\"\n",
        "            for period in periods:\n",
        "                number = period.get('number')\n",
        "                short_forecast = period.get('shortForecast', '').strip()\n",
        "                if number is not None and short_forecast:\n",
        "                    day_forecast = f\"day {number} forecast suggests {short_forecast}\"\n",
        "                    merged_content += f\"{day_forecast} \"\n",
        "            merged_content = merged_content.strip()\n",
        "            logging.debug(f\"Merged Short Forecasts Paragraph: {merged_content}\")\n",
        "            return merged_content\n",
        "        except KeyError as key_err:\n",
        "            logging.error(f\"Key error while extracting short forecasts: {key_err}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting short forecasts: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Weather Summarizer ----------------------\n",
        "\n",
        "class WeatherSummarizer:\n",
        "    \"\"\"\n",
        "    Generates summaries using OpenAI GPT-4o-mini (via the new v1 migration).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the summarizer.\n",
        "        Loads spaCy for potential text processing if needed.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Loading spaCy language model.\")\n",
        "            self.nlp = spacy.load(\"en_core_web_trf\")\n",
        "            logging.info(\"spaCy model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to load spaCy model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize(self, paragraphs: List[str], max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        (Optional) Summarize a list of paragraphs using GPT-4o-mini.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating summary with GPT-4o-mini (optional).\")\n",
        "            full_text = \" \".join(paragraphs)\n",
        "\n",
        "            # Use the new openai v1 style calls\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant summarizing weather data.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": full_text\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize_merged_detailed_forecasts(self, merged_content: str, max_length: int = 700, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the merged detailed forecasts using GPT-4o-mini.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating GPT-4o-mini summary for merged detailed forecasts.\")\n",
        "\n",
        "            doc = self.nlp(merged_content)\n",
        "            sentences = [sent.text for sent in doc.sents]\n",
        "            paragraph = \" \".join(sentences)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant summarizing weather forecasts in detail.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": paragraph\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during detailed forecasts summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "    def summarize_merged_short_forecasts(self, merged_content: str, max_length: int = 150, min_length: int = 40) -> str:\n",
        "        \"\"\"\n",
        "        Generates a summary from the merged short forecasts using GPT-4o-mini.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logging.info(\"Generating GPT-4o-mini summary for merged short forecasts.\")\n",
        "\n",
        "            doc = self.nlp(merged_content)\n",
        "            sentences = [sent.text for sent in doc.sents]\n",
        "            paragraph = \" \".join(sentences)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful assistant summarizing short weather forecasts.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": paragraph\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during short forecasts summarization: {e}\")\n",
        "            raise\n",
        "\n",
        "# ---------------------- Input Validation ----------------------\n",
        "\n",
        "def validate_coordinates(latitude: float, longitude: float) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Validates the latitude and longitude values.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    if not (-90 <= latitude <= 90):\n",
        "        errors.append(\"Latitude must be between -90 and 90.\")\n",
        "    if not (-180 <= longitude <= 180):\n",
        "        errors.append(\"Longitude must be between -180 and 180.\")\n",
        "    if errors:\n",
        "        return \" \".join(errors)\n",
        "    return None\n",
        "\n",
        "# ---------------------- Gradio Interface Function ----------------------\n",
        "\n",
        "def weather_gradio_interface(latitude: float, longitude: float) -> Tuple[str, str, str, str, str, str]:\n",
        "    \"\"\"\n",
        "    Gradio interface function to fetch, parse, and summarize weather data.\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - Raw NOAA API response (as text)\n",
        "            - Summary of forecast\n",
        "            - Merged Detailed Forecasts\n",
        "            - Summarized Detailed Forecast\n",
        "            - Merged Short Forecasts\n",
        "            - Summarized Short Forecast\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    validation_error = validate_coordinates(latitude, longitude)\n",
        "    if validation_error:\n",
        "        logging.error(f\"Input validation failed: {validation_error}\")\n",
        "        return (\n",
        "            validation_error,\n",
        "            \"Unable to generate summary due to invalid inputs.\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\"\n",
        "        )\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = NOAADataFetcher(user_agent=USER_AGENT)\n",
        "    parser = WeatherDataParser()\n",
        "    summarizer = WeatherSummarizer()\n",
        "\n",
        "    try:\n",
        "        # Fetch data\n",
        "        forecast_data = fetcher.fetch_forecast(latitude, longitude)\n",
        "        if not forecast_data:\n",
        "            logging.error(\"No forecast data retrieved.\")\n",
        "            return (\n",
        "                \"No forecast data retrieved.\",\n",
        "                \"Unable to generate summary.\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        # Parse data\n",
        "        paragraphs = parser.parse_forecast(forecast_data, days=FORECAST_DAYS)\n",
        "        if not paragraphs:\n",
        "            logging.error(\"No weather information available to summarize.\")\n",
        "            return (\n",
        "                \"No weather information available to summarize.\",\n",
        "                \"Unable to generate summary.\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        # Summarize (using GPT-4o-mini)\n",
        "        summary = summarizer.summarize(paragraphs)\n",
        "\n",
        "        # Prepare raw data\n",
        "        raw_data = json.dumps(forecast_data, indent=2)\n",
        "\n",
        "        # Extract/Merge & Summarize Detailed Forecasts\n",
        "        merged_detailed_forecasts = parser.extract_and_merge_detailed_forecasts(forecast_data)\n",
        "        merged_detailed_summary = summarizer.summarize_merged_detailed_forecasts(merged_detailed_forecasts)\n",
        "\n",
        "        # Extract/Merge & Summarize Short Forecasts\n",
        "        merged_short_forecasts = parser.extract_and_merge_short_forecasts(forecast_data)\n",
        "        merged_short_summary = summarizer.summarize_merged_short_forecasts(merged_short_forecasts)\n",
        "\n",
        "        return (\n",
        "            raw_data,\n",
        "            summary,\n",
        "            merged_detailed_forecasts,\n",
        "            merged_detailed_summary,\n",
        "            merged_short_forecasts,\n",
        "            merged_short_summary\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"Error in Gradio interface: {e}\")\n",
        "        return (\n",
        "            f\"An error occurred: {e}\",\n",
        "            \"Unable to generate summary.\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "            \"\"\n",
        "        )\n",
        "\n",
        "# ---------------------- Main Execution ----------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if HF_TOKEN:\n",
        "        os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
        "        logging.info(\"Hugging Face token found and set.\")\n",
        "    else:\n",
        "        logging.warning(\"\"\"\n",
        "        Hugging Face token (HF_TOKEN) not found.\n",
        "        Proceeding without authentication may lead to rate limiting.\n",
        "        \"\"\")\n",
        "\n",
        "    import torch\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    if device == 0:\n",
        "        logging.info(\"GPU is available, though not used by GPT-4o-mini here.\")\n",
        "    else:\n",
        "        logging.info(\"Using CPU for summarization calls to GPT-4o-mini.\")\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# NOAA API Weather Forecast Summarizer by using Spacy and OpenAI\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Developed by **Partha Pratim Ray**, **parthapratimray1986@gmail.com**\n",
        "        \"\"\")\n",
        "        gr.Markdown(\"\"\"\n",
        "        Enter the **latitude** and **longitude** of a location to retrieve a summarized weather forecast.\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            latitude_input = gr.Number(label=\"Latitude\", value=32.7767)\n",
        "            longitude_input = gr.Number(label=\"Longitude\", value=-96.7970)\n",
        "\n",
        "        submit_button = gr.Button(\"Submit\")\n",
        "\n",
        "        with gr.Tab(\"Raw Data\"):\n",
        "            raw_output = gr.Textbox(label=\"Raw NOAA API Response\", lines=20, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary_output = gr.Textbox(label=\"Summarized Weather Forecast\", lines=10, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Detailed Forecasts\"):\n",
        "            merged_detailed_forecast_output = gr.Textbox(label=\"Merged Detailed Forecasts\", lines=30, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Detailed Forecast Summary\"):\n",
        "            merged_detailed_summary_output = gr.Textbox(label=\"Summarized Detailed Forecast\", lines=5, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Short Forecasts\"):\n",
        "            merged_short_forecast_output = gr.Textbox(label=\"Merged Short Forecasts\", lines=30, interactive=False)\n",
        "\n",
        "        with gr.Tab(\"Short Forecast Summary\"):\n",
        "            merged_short_summary_output = gr.Textbox(label=\"Summarized Short Forecasts\", lines=5, interactive=False)\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=weather_gradio_interface,\n",
        "            inputs=[latitude_input, longitude_input],\n",
        "            outputs=[\n",
        "                raw_output,\n",
        "                summary_output,\n",
        "                merged_detailed_forecast_output,\n",
        "                merged_detailed_summary_output,\n",
        "                merged_short_forecast_output,\n",
        "                merged_short_summary_output\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **Note:** Ensure that the latitude and longitude values are valid. For example:\n",
        "        - **Dallas, TX:** Latitude `32.7767`, Longitude `-96.7970`\n",
        "        - **New York City, NY:** Latitude `40.7128`, Longitude `-74.0060`\n",
        "        \"\"\")\n",
        "\n",
        "    demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f577c5a18d34b23bf05c2a7dbfed248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8639da808d8940b8948b260380d4cabb",
              "IPY_MODEL_e0f7861b3117495f90b37059419e3aa3",
              "IPY_MODEL_ada246812a5f492a984447d141db25c1"
            ],
            "layout": "IPY_MODEL_5c309b7a90a349d9929b117525a21f29"
          }
        },
        "8639da808d8940b8948b260380d4cabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d0af05ea5244f2a92a0c2beed74f46",
            "placeholder": "​",
            "style": "IPY_MODEL_b94d2593581b4570a72404d8d16e4756",
            "value": "config.json: 100%"
          }
        },
        "e0f7861b3117495f90b37059419e3aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_493310099b014ca89a2793f3fae98e3f",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94e64e1fed494c52959af81c478394ed",
            "value": 1585
          }
        },
        "ada246812a5f492a984447d141db25c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e59d6804125469086b44d0ddc6ae424",
            "placeholder": "​",
            "style": "IPY_MODEL_6fbc8672b1ca4e9ab2a58d5ff6129e88",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 108kB/s]"
          }
        },
        "5c309b7a90a349d9929b117525a21f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d0af05ea5244f2a92a0c2beed74f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94d2593581b4570a72404d8d16e4756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "493310099b014ca89a2793f3fae98e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e64e1fed494c52959af81c478394ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e59d6804125469086b44d0ddc6ae424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fbc8672b1ca4e9ab2a58d5ff6129e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f1ea75388684987af26390454924d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da38f816e95244e5a2641d8ceefdcd15",
              "IPY_MODEL_94ca0baefcd944b58a7657085d47073a",
              "IPY_MODEL_e80914275f8f4eb88aca04dca74021d5"
            ],
            "layout": "IPY_MODEL_49cd21d2648847ed9419f003e0f797ca"
          }
        },
        "da38f816e95244e5a2641d8ceefdcd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_458cc19f09fb4fe1be2af54b8236b8a9",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9963ef96d743438a405e7c978c200a",
            "value": "model.safetensors: 100%"
          }
        },
        "94ca0baefcd944b58a7657085d47073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed96ddc966a4483e9cfd8abb8e1e570a",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8fc4ad9576240b890aa00ef303edc08",
            "value": 1625222120
          }
        },
        "e80914275f8f4eb88aca04dca74021d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a55e5cdc564beeab0d8e8eda31f43d",
            "placeholder": "​",
            "style": "IPY_MODEL_90b7807bb2c248f4bb272f310ba1dc46",
            "value": " 1.63G/1.63G [00:11&lt;00:00, 129MB/s]"
          }
        },
        "49cd21d2648847ed9419f003e0f797ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458cc19f09fb4fe1be2af54b8236b8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9963ef96d743438a405e7c978c200a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed96ddc966a4483e9cfd8abb8e1e570a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fc4ad9576240b890aa00ef303edc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16a55e5cdc564beeab0d8e8eda31f43d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b7807bb2c248f4bb272f310ba1dc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f210c723a31e40eba67ce43da00394b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b5a11135cc94438bc2ae769da9725dd",
              "IPY_MODEL_7d89a4df43314810b5ca7405d53d9eca",
              "IPY_MODEL_083b8047c9014a64b79f67e055b90c86"
            ],
            "layout": "IPY_MODEL_b97a56a39aa046c7a1b0be31784b3641"
          }
        },
        "5b5a11135cc94438bc2ae769da9725dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51050718cb8441b580a551ef1f245065",
            "placeholder": "​",
            "style": "IPY_MODEL_d415697d704245bb876114dfa6220eb2",
            "value": "generation_config.json: 100%"
          }
        },
        "7d89a4df43314810b5ca7405d53d9eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41328f3b3a824d57bc64b409f626df70",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4933bc811431441c90e3336c85c5aeed",
            "value": 363
          }
        },
        "083b8047c9014a64b79f67e055b90c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48193d767eb047a38676ca4039474d29",
            "placeholder": "​",
            "style": "IPY_MODEL_1bac097b31074a28ae1cdce5028b2242",
            "value": " 363/363 [00:00&lt;00:00, 25.7kB/s]"
          }
        },
        "b97a56a39aa046c7a1b0be31784b3641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51050718cb8441b580a551ef1f245065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d415697d704245bb876114dfa6220eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41328f3b3a824d57bc64b409f626df70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4933bc811431441c90e3336c85c5aeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48193d767eb047a38676ca4039474d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bac097b31074a28ae1cdce5028b2242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15bd4b8605347bc88f1bbc6af9df971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6e9102a6d4546d7bb430563174c34d8",
              "IPY_MODEL_a81ba9dfe9b8478c9a223a78b4f67e6c",
              "IPY_MODEL_377a17c8d37a45058a8e45a97816f082"
            ],
            "layout": "IPY_MODEL_8eeb2218bee848808021730bab123c96"
          }
        },
        "a6e9102a6d4546d7bb430563174c34d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec592025b3994a7992df6f881294774a",
            "placeholder": "​",
            "style": "IPY_MODEL_8d69a13b662b499a8b02a91231a42980",
            "value": "vocab.json: 100%"
          }
        },
        "a81ba9dfe9b8478c9a223a78b4f67e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aae2b07073b4caab72f6d8bd4fb698a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e53de26c836482688df4622bc6e46d1",
            "value": 898823
          }
        },
        "377a17c8d37a45058a8e45a97816f082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf7bf6f2ec8417f8070744a08ffa451",
            "placeholder": "​",
            "style": "IPY_MODEL_ddcbafb4751a4010911ffdb9a8b9dedb",
            "value": " 899k/899k [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "8eeb2218bee848808021730bab123c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec592025b3994a7992df6f881294774a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d69a13b662b499a8b02a91231a42980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aae2b07073b4caab72f6d8bd4fb698a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e53de26c836482688df4622bc6e46d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdf7bf6f2ec8417f8070744a08ffa451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddcbafb4751a4010911ffdb9a8b9dedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c83e4c71a2467bbb37200eb9a9dd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c5e26c7c4c54b05a858d368f84d4b4b",
              "IPY_MODEL_650befdd647a4ed3a079fb4e02254cbe",
              "IPY_MODEL_22772e67433542389a1a4d08f17aec34"
            ],
            "layout": "IPY_MODEL_0463355d89f44f8080128e6597ce63c5"
          }
        },
        "6c5e26c7c4c54b05a858d368f84d4b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013fec8da569414aa1dcf6160f02b3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_6146de77d4274a87bc4620eabd4489cc",
            "value": "merges.txt: 100%"
          }
        },
        "650befdd647a4ed3a079fb4e02254cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f2088433284da0b6ac3ba985f4347f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ded762e089d41f1847a42af3522fb1c",
            "value": 456318
          }
        },
        "22772e67433542389a1a4d08f17aec34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb289860a1d47f1ae28beb98b71caa9",
            "placeholder": "​",
            "style": "IPY_MODEL_aa77bdce55e3486baaa5c1243482d113",
            "value": " 456k/456k [00:00&lt;00:00, 1.32MB/s]"
          }
        },
        "0463355d89f44f8080128e6597ce63c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "013fec8da569414aa1dcf6160f02b3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6146de77d4274a87bc4620eabd4489cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f2088433284da0b6ac3ba985f4347f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ded762e089d41f1847a42af3522fb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbb289860a1d47f1ae28beb98b71caa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa77bdce55e3486baaa5c1243482d113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a538028cb4e4f4d936f60e3ae67d88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5f2e9c233c042fcbe8ecd4726723f18",
              "IPY_MODEL_d07d17d3a2b44882bb28721552804a71",
              "IPY_MODEL_b6e8bb0758db442e80ebeae46db2b599"
            ],
            "layout": "IPY_MODEL_ff5e7a2d7d65436a950d27185a739a8a"
          }
        },
        "b5f2e9c233c042fcbe8ecd4726723f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_176753ef63344f41b0285850eb01662b",
            "placeholder": "​",
            "style": "IPY_MODEL_11b0d5f695554a208e9b890f1c35c550",
            "value": "tokenizer.json: 100%"
          }
        },
        "d07d17d3a2b44882bb28721552804a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1c0431fdb24882bfa3f214b3940717",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5246de9f33a47339418d6b34600e424",
            "value": 1355863
          }
        },
        "b6e8bb0758db442e80ebeae46db2b599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28920e8aa68e461bbba07f1514448504",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f2a65d018044dbb364c3995d17f1cf",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "ff5e7a2d7d65436a950d27185a739a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176753ef63344f41b0285850eb01662b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b0d5f695554a208e9b890f1c35c550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df1c0431fdb24882bfa3f214b3940717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5246de9f33a47339418d6b34600e424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28920e8aa68e461bbba07f1514448504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f2a65d018044dbb364c3995d17f1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}